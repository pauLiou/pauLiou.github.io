---
jupyter:
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.7.12
  nbformat: 4
  nbformat_minor: 5
  papermill:
    default_parameters: {}
    duration: 358.470476
    end_time: "2022-10-17T16:02:38.318867"
    environment_variables: {}
    input_path: \_\_notebook\_\_.ipynb
    output_path: \_\_notebook\_\_.ipynb
    parameters: {}
    start_time: "2022-10-17T15:56:39.848391"
    version: 2.3.4
---

::: {.cell .code _cell_guid="b1076dfc-b9ad-4769-8c92-a6c4dae69d19" _uuid="8f2839f25d086af736a60e9eeb907d3b93b6e0e5" execution="{\"iopub.status.busy\":\"2022-10-17T12:27:09.244948Z\",\"shell.execute_reply.started\":\"2022-10-17T12:27:09.245531Z\",\"iopub.status.idle\":\"2022-10-17T12:27:09.259322Z\",\"iopub.execute_input\":\"2022-10-17T12:27:09.245562Z\",\"shell.execute_reply\":\"2022-10-17T12:27:09.254640Z\"}" papermill="{\"status\":\"completed\",\"duration\":6.126e-3,\"end_time\":\"2022-10-17T15:56:47.920005\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:47.913879\"}" tags="[]"}
``` {.python}
```
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":4.74e-3,\"end_time\":\"2022-10-17T15:56:47.930092\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:47.925352\"}" tags="[]"}
```{=html}
<p style="background-color:#90EE90;color:black;font-size:45px;text-align:center;border-radius:9px 9px;font-weight:bold;border:2px black;">Image Classifier - Men vs Women ~95% Accuracy</p>
```
:::

::: {.cell .code execution_count="1" execution="{\"iopub.status.busy\":\"2022-10-17T15:56:47.942739Z\",\"iopub.status.idle\":\"2022-10-17T15:56:47.951820Z\",\"iopub.execute_input\":\"2022-10-17T15:56:47.943917Z\",\"shell.execute_reply\":\"2022-10-17T15:56:47.950945Z\"}" papermill="{\"status\":\"completed\",\"duration\":1.7696e-2,\"end_time\":\"2022-10-17T15:56:47.954032\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:47.936336\"}" tags="[]"}
``` {.python}
# Project Planning --
# 1. The first step for this project is to get a data-set that will serve us well for training the model.
# 2. I've identified 3 good sets that I will download and merge into a large usable set available here:

#    Giant Face Recognition Set - https://www.kaggle.com/datasets/pauliou/giant-face-recognition-set

# This way we can have multiple different styles of faces from different databases to train on.

# 3. We are going to train our model using the Keras Xception Application which has shown remarkably good weights for binary classification.
# 4. We will use Image Augmentation techniques from the ImageDataGenerator keras preprocessing toolset.
# 5. The model will be trained with pre-tuned weights based on my research and from trying different setups until I was satisfied.
# 6. The evaulation will be tested using a sample that is left out of the 3 merged sets.    
```
:::

::: {.cell .code execution_count="2" execution="{\"iopub.status.busy\":\"2022-10-17T15:56:47.967035Z\",\"iopub.status.idle\":\"2022-10-17T15:56:53.940658Z\",\"iopub.execute_input\":\"2022-10-17T15:56:47.967393Z\",\"shell.execute_reply\":\"2022-10-17T15:56:53.939682Z\"}" papermill="{\"status\":\"completed\",\"duration\":5.983853,\"end_time\":\"2022-10-17T15:56:53.943067\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:47.959214\"}" tags="[]"}
``` {.python}
import random

import os,sys
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm 


import tensorflow as tf, tensorflow.keras.backend as K
## Bare minimum library requirement

import tensorflow.keras
#Keras provide API for Augmentation helps in generation

import matplotlib.pyplot as plt
```
:::

::: {.cell .code execution_count="3" execution="{\"iopub.status.busy\":\"2022-10-17T15:56:53.955532Z\",\"iopub.status.idle\":\"2022-10-17T15:56:53.962266Z\",\"iopub.execute_input\":\"2022-10-17T15:56:53.956107Z\",\"shell.execute_reply\":\"2022-10-17T15:56:53.961286Z\"}" papermill="{\"status\":\"completed\",\"duration\":1.6941e-2,\"end_time\":\"2022-10-17T15:56:53.966109\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:53.949168\"}" tags="[]"}
``` {.python}
#List down all directories in "/kaggle/input/"

source = '../input/giant-face-recognition-set/Data/' #  this is the dataset that I created 

 # defining some dirs
trainDir = source + 'Training/'
testDir = source + 'Testing/'
validDir = source + 'Validation/'
predictionDir = source + 'Unknown/'


print('Directory:',source)
print('Directory:',trainDir)
print('Directory:',testDir)
print('Directory:',validDir)
print('Directory:',predictionDir)
```

::: {.output .stream .stdout}
    Directory: ../input/giant-face-recognition-set/Data/
    Directory: ../input/giant-face-recognition-set/Data/Training/
    Directory: ../input/giant-face-recognition-set/Data/Testing/
    Directory: ../input/giant-face-recognition-set/Data/Validation/
    Directory: ../input/giant-face-recognition-set/Data/Unknown/
:::
:::

::: {.cell .code execution_count="4" execution="{\"iopub.status.busy\":\"2022-10-17T15:56:53.978744Z\",\"iopub.status.idle\":\"2022-10-17T15:56:53.983903Z\",\"iopub.execute_input\":\"2022-10-17T15:56:53.979557Z\",\"shell.execute_reply\":\"2022-10-17T15:56:53.982829Z\"}" papermill="{\"status\":\"completed\",\"duration\":1.3609e-2,\"end_time\":\"2022-10-17T15:56:53.985906\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:53.972297\"}" tags="[]"}
``` {.python}
batch_size = 10
image_shape = (256,256)
```
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":4.942e-3,\"end_time\":\"2022-10-17T15:56:53.996125\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:53.991183\"}" tags="[]"}
## `<p style="background-color:#90EE90;color:black;font-size:30px;text-align:center;border-radius:12px 10px;border:2px;">`{=html} 1. Image Extraction and Augmentation `</p>`{=html} {#-1-image-extraction-and-augmentation-}
:::

::: {.cell .code execution_count="5" execution="{\"iopub.status.busy\":\"2022-10-17T15:56:54.007588Z\",\"iopub.status.idle\":\"2022-10-17T15:56:54.016251Z\",\"iopub.execute_input\":\"2022-10-17T15:56:54.008539Z\",\"shell.execute_reply\":\"2022-10-17T15:56:54.015328Z\"}" papermill="{\"status\":\"completed\",\"duration\":1.7078e-2,\"end_time\":\"2022-10-17T15:56:54.018313\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:54.001235\"}" tags="[]"}
``` {.python}
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# here we are going to create the image augmentation parameters for training the model
def image_generator(directory):    
    data_import = ImageDataGenerator(horizontal_flip = True,
                                           width_shift_range = 0.2,
                                           height_shift_range = 0.2,
                                           zoom_range = 0.2,
                                           shear_range = 0.2,
                                           rotation_range = 20,
                                           rescale=1./255,
                                           fill_mode='nearest'
                                      )
    data = data_import.flow_from_directory(directory,
                                          target_size=image_shape,
                                          batch_size=batch_size,
                                          class_mode='binary',
                                          color_mode='rgb',
                                          shuffle=True)
    
    return data

# here we are defining the binary validity test data-sets (separate data)
def valid_generator(directory):
    data_import = ImageDataGenerator(rescale=1./255)

    data = data_import.flow_from_directory(directory,
                                           target_size=image_shape,
                                           batch_size=batch_size,
                                           class_mode='binary',
                                           color_mode='rgb',
                                           shuffle=False)
    return data
```
:::

::: {.cell .code execution_count="6" execution="{\"iopub.status.busy\":\"2022-10-17T15:56:54.029830Z\",\"iopub.status.idle\":\"2022-10-17T16:00:25.500888Z\",\"iopub.execute_input\":\"2022-10-17T15:56:54.031550Z\",\"shell.execute_reply\":\"2022-10-17T16:00:25.499832Z\"}" papermill="{\"status\":\"completed\",\"duration\":211.485054,\"end_time\":\"2022-10-17T16:00:25.508626\",\"exception\":false,\"start_time\":\"2022-10-17T15:56:54.023572\"}" tags="[]"}
``` {.python}
# run the image augmentation and extract tool on the three sets of data we will use
train_data = image_generator(trainDir)
test_data = image_generator(testDir)
valid_data = valid_generator(validDir)
```

::: {.output .stream .stdout}
    Found 242774 images belonging to 2 classes.
    Found 20001 images belonging to 2 classes.
    Found 34247 images belonging to 2 classes.
:::
:::

::: {.cell .code execution_count="7" execution="{\"iopub.status.busy\":\"2022-10-17T16:00:25.521097Z\",\"iopub.status.idle\":\"2022-10-17T16:00:25.528663Z\",\"iopub.execute_input\":\"2022-10-17T16:00:25.521417Z\",\"shell.execute_reply\":\"2022-10-17T16:00:25.527791Z\"}" papermill="{\"status\":\"completed\",\"duration\":1.5935e-2,\"end_time\":\"2022-10-17T16:00:25.530800\",\"exception\":false,\"start_time\":\"2022-10-17T16:00:25.514865\"}" tags="[]"}
``` {.python}
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import Xception
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img, img_to_array
```
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":5.072e-3,\"end_time\":\"2022-10-17T16:00:25.541577\",\"exception\":false,\"start_time\":\"2022-10-17T16:00:25.536505\"}" tags="[]"}
## `<p style="background-color:#90EE90;color:black;font-size:30px;text-align:center;border-radius:12px 10px;border:2px;">`{=html} 2. Building the Model `</p>`{=html} {#-2-building-the-model-}
:::

::: {.cell .code execution_count="8" execution="{\"iopub.status.busy\":\"2022-10-17T16:00:25.552774Z\",\"iopub.status.idle\":\"2022-10-17T16:00:30.456748Z\",\"iopub.execute_input\":\"2022-10-17T16:00:25.553702Z\",\"shell.execute_reply\":\"2022-10-17T16:00:30.455737Z\"}" papermill="{\"status\":\"completed\",\"duration\":4.91259,\"end_time\":\"2022-10-17T16:00:30.459306\",\"exception\":false,\"start_time\":\"2022-10-17T16:00:25.546716\"}" tags="[]"}
``` {.python}
pretrained_model = tf.keras.applications.Xception( #  here is the pretrained model that we will be applying to our model
        include_top=False,
        weights= 'imagenet',
        input_shape=(*[256,256],3))

pretrained_model.trainable = True #  we are making the model weights adjustable to see if we can squeeze out some improvement
```

::: {.output .stream .stderr}
    2022-10-17 16:00:25.695730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:25.810180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:25.811303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:25.813335: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2022-10-17 16:00:25.813676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:25.814645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:25.815556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:28.251268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:28.252164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:28.252916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-10-17 16:00:28.253799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
:::

::: {.output .stream .stdout}
    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5
    83689472/83683744 [==============================] - 0s 0us/step
    83697664/83683744 [==============================] - 0s 0us/step
:::
:::

::: {.cell .code execution_count="9" collapsed="true" execution="{\"iopub.status.busy\":\"2022-10-17T16:00:30.472483Z\",\"iopub.status.idle\":\"2022-10-17T16:00:32.288096Z\",\"iopub.execute_input\":\"2022-10-17T16:00:30.473354Z\",\"shell.execute_reply\":\"2022-10-17T16:00:32.286653Z\"}" jupyter="{\"outputs_hidden\":true}" papermill="{\"status\":\"completed\",\"duration\":1.834023,\"end_time\":\"2022-10-17T16:00:32.299457\",\"exception\":false,\"start_time\":\"2022-10-17T16:00:30.465434\"}" tags="[]"}
``` {.python}
from keras.models import Model
from keras.layers import Flatten, Dense, GlobalMaxPooling2D, Dropout


pretrained_model.trainable = False

last_layer = pretrained_model.get_layer('block14_sepconv2_act')
last_output = last_layer.output
x = BatchNormalization()
x = GlobalMaxPooling2D()(last_output)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.3)(x) 
x = Dense(1, activation='sigmoid')(x)

model = Model(pretrained_model.input,x)
opt = keras.optimizers.Adagrad(learning_rate=0.001)

#Model compilation
model.compile(
    optimizer= opt,
    loss='binary_crossentropy',
    metrics=['accuracy']
    )

#model summary
tf.keras.utils.plot_model(model)
```

::: {.output .execute_result execution_count="9"}
![](vertopal_04cb403177b04b4cbbc6e5647ef19996/c6a1f1b27a424d7a5cc7626fa7a9336362673413.png)
:::
:::

::: {.cell .code execution_count="10" execution="{\"iopub.status.busy\":\"2022-10-17T16:00:32.331893Z\",\"iopub.status.idle\":\"2022-10-17T16:00:32.338265Z\",\"iopub.execute_input\":\"2022-10-17T16:00:32.332261Z\",\"shell.execute_reply\":\"2022-10-17T16:00:32.337290Z\"}" papermill="{\"status\":\"completed\",\"duration\":2.5248e-2,\"end_time\":\"2022-10-17T16:00:32.340363\",\"exception\":false,\"start_time\":\"2022-10-17T16:00:32.315115\"}" tags="[]"}
``` {.python}
# here we will define the callback settings for early stopping and saving

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor = 'val_loss',
    patience = 5, # stops if no min_delta improvement after 5 epochs
    min_delta = 0.01,
    mode = 'auto')
checkpoint_filepath = './'
save_best = tf.keras.callbacks.ModelCheckpoint(
    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',
    monitor = "val_accuracy",
    verbose = 0,
    save_best_only= True,
    mode = "max",
    save_freq = "epoch")
```
:::

::: {.cell .code execution_count="11" execution="{\"iopub.status.busy\":\"2022-10-17T16:00:32.371374Z\",\"iopub.status.idle\":\"2022-10-17T16:01:19.982763Z\",\"iopub.execute_input\":\"2022-10-17T16:00:32.371717Z\",\"shell.execute_reply\":\"2022-10-17T16:01:19.981756Z\"}" papermill="{\"status\":\"completed\",\"duration\":47.630035,\"end_time\":\"2022-10-17T16:01:19.985144\",\"exception\":false,\"start_time\":\"2022-10-17T16:00:32.355109\"}" tags="[]"}
``` {.python}
# here we are fitting the model 
epochs = 12
batch_size=64
history = model.fit(train_data,
                steps_per_epoch = 12, # changed these around a fair bit just trying different setups
                epochs = 100,
                validation_data = valid_data,
                validation_steps = len(valid_data)//batch_size,
                callbacks = [early_stopping,save_best])
```

::: {.output .stream .stderr}
    2022-10-17 16:00:32.660856: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
:::

::: {.output .stream .stdout}
    Epoch 1/100
:::

::: {.output .stream .stderr}
    2022-10-17 16:00:36.309184: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005
:::

::: {.output .stream .stdout}
    12/12 [==============================] - 15s 498ms/step - loss: 0.7366 - accuracy: 0.5083 - val_loss: 0.3516 - val_accuracy: 0.9415
:::

::: {.output .stream .stderr}
    /opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
      category=CustomMaskWarning)
:::

::: {.output .stream .stdout}
    Epoch 2/100
    12/12 [==============================] - 5s 462ms/step - loss: 0.5921 - accuracy: 0.7250 - val_loss: 0.6594 - val_accuracy: 0.6245
    Epoch 3/100
    12/12 [==============================] - 5s 410ms/step - loss: 0.4646 - accuracy: 0.7667 - val_loss: 0.4675 - val_accuracy: 0.7943
    Epoch 4/100
    12/12 [==============================] - 5s 404ms/step - loss: 0.4695 - accuracy: 0.7750 - val_loss: 0.3443 - val_accuracy: 0.8925
    Epoch 5/100
    12/12 [==============================] - 5s 388ms/step - loss: 0.3557 - accuracy: 0.8167 - val_loss: 0.3717 - val_accuracy: 0.8660
    Epoch 6/100
    12/12 [==============================] - 5s 388ms/step - loss: 0.3023 - accuracy: 0.8500 - val_loss: 0.5903 - val_accuracy: 0.6906
:::
:::

::: {.cell .code execution_count="12" execution="{\"iopub.status.busy\":\"2022-10-17T16:01:20.026727Z\",\"iopub.status.idle\":\"2022-10-17T16:01:20.827594Z\",\"iopub.execute_input\":\"2022-10-17T16:01:20.027698Z\",\"shell.execute_reply\":\"2022-10-17T16:01:20.826584Z\"}" papermill="{\"status\":\"completed\",\"duration\":0.824491,\"end_time\":\"2022-10-17T16:01:20.829793\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:20.005302\"}" tags="[]"}
``` {.python}
# plotting the loss and accuracy 
history_df = pd.DataFrame(history.history)
history_df.loc[:, ['loss', 'val_loss','accuracy','val_accuracy']].plot()
plt.ylim(0,1)
print("Minimum validation loss: {}".format(history_df['val_loss'].min()))
```

::: {.output .stream .stdout}
    Minimum validation loss: 0.34434348344802856
:::

::: {.output .display_data}
![](vertopal_04cb403177b04b4cbbc6e5647ef19996/802f8dfc49cca02062cccbc2c444587938c9d674.png)
:::
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":2.0021e-2,\"end_time\":\"2022-10-17T16:01:20.869833\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:20.849812\"}" tags="[]"}
## `<p style="background-color:#90EE90;color:black;font-size:30px;text-align:center;border-radius:12px 10px;border:2px;">`{=html} 3. Model Results and Evaluation `</p>`{=html} {#-3-model-results-and-evaluation-}
:::

::: {.cell .code execution_count="13" execution="{\"iopub.status.busy\":\"2022-10-17T16:01:20.912548Z\",\"iopub.status.idle\":\"2022-10-17T16:01:31.511924Z\",\"iopub.execute_input\":\"2022-10-17T16:01:20.913339Z\",\"shell.execute_reply\":\"2022-10-17T16:01:31.510402Z\"}" papermill="{\"status\":\"completed\",\"duration\":10.62374,\"end_time\":\"2022-10-17T16:01:31.514331\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:20.890591\"}" tags="[]"}
``` {.python}
#testing the model using the evaluate function on unseen data
test_loss, test_acc = history.model.evaluate(test_data, steps=50)
print('test acc:', test_acc)
print('test_loss:',test_loss)
```

::: {.output .stream .stdout}
    50/50 [==============================] - 10s 205ms/step - loss: 0.2810 - accuracy: 0.8880
    test acc: 0.8880000114440918
    test_loss: 0.28100520372390747
:::
:::

::: {.cell .code execution_count="14" execution="{\"iopub.status.busy\":\"2022-10-17T16:01:31.560215Z\",\"iopub.status.idle\":\"2022-10-17T16:01:31.569411Z\",\"iopub.execute_input\":\"2022-10-17T16:01:31.560526Z\",\"shell.execute_reply\":\"2022-10-17T16:01:31.568439Z\"}" papermill="{\"status\":\"completed\",\"duration\":3.4555e-2,\"end_time\":\"2022-10-17T16:01:31.571372\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:31.536817\"}" tags="[]"}
``` {.python}
# here is a fairly poorly written function that at least works, it just gives us a random group of data output

def img_prediction(data,row,col):
    rows=row
    cols =col
    img_count = 0

    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(15,15))
    plus = random.randint(1,len(data)-16)

    for i in range(rows):
        for j in range(cols):        
            if img_count < 16:
                r_size = cv2.resize(data[img_count+plus][0][0],(256,256))
                roi = cv2.cvtColor(r_size, cv2.COLOR_BGR2RGB)
                finish = roi.reshape(1,256,256,3)
                y_pre = history.model.predict(finish)
                axes[i, j].imshow(data[img_count+plus][0][0])
                x = str('Male' if y_pre > 0.5 else 'Female')
                axes[i, j].set_title(f'Prediction: {x}')
                axes[i, j].axes.get_xaxis().set_visible(False)
                axes[i, j].axes.get_yaxis().set_visible(False)
                img_count+=1
    
```
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":2.1931e-2,\"end_time\":\"2022-10-17T16:01:31.614971\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:31.593040\"}" tags="[]"}
## `<p style="background-color:#90EE90;color:black;font-size:30px;text-align:center;border-radius:12px 10px;border:2px;">`{=html} 4. Model Prediction of Unseen Data`</p>`{=html} {#-4-model-prediction-of-unseen-data}
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":2.2443e-2,\"end_time\":\"2022-10-17T16:01:31.660017\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:31.637574\"}" tags="[]"}
`<font size="3" color="black">`{=html} This first set of data is based
on the same style as the training data. So we are expecting to have
pretty good accuracy here. We are currently sitting at around 95%
accuracy overall for similary style images!
:::

::: {.cell .code execution_count="15" execution="{\"iopub.status.busy\":\"2022-10-17T16:01:31.706328Z\",\"iopub.status.idle\":\"2022-10-17T16:01:39.627434Z\",\"iopub.execute_input\":\"2022-10-17T16:01:31.707427Z\",\"shell.execute_reply\":\"2022-10-17T16:01:39.626577Z\"}" papermill="{\"status\":\"completed\",\"duration\":7.956039,\"end_time\":\"2022-10-17T16:01:39.638790\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:31.682751\"}" tags="[]"}
``` {.python}
img_prediction(test_data,4,4)
```

::: {.output .display_data}
![](vertopal_04cb403177b04b4cbbc6e5647ef19996/5cc550e5d0bcf53f1b4c10dff7de120fb07562de.png)
:::
:::

::: {.cell .code execution_count="16" execution="{\"iopub.status.busy\":\"2022-10-17T16:01:39.708722Z\",\"iopub.status.idle\":\"2022-10-17T16:01:58.862342Z\",\"iopub.execute_input\":\"2022-10-17T16:01:39.709718Z\",\"shell.execute_reply\":\"2022-10-17T16:01:58.861123Z\"}" papermill="{\"status\":\"completed\",\"duration\":19.191713,\"end_time\":\"2022-10-17T16:01:58.864575\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:39.672862\"}" tags="[]"}
``` {.python}
unknown_data = image_generator(predictionDir) # using a further unseen group of data with a fairly different image-style
```

::: {.output .stream .stdout}
    Found 23709 images belonging to 1 classes.
:::
:::

::: {.cell .markdown papermill="{\"status\":\"completed\",\"duration\":3.2761e-2,\"end_time\":\"2022-10-17T16:01:58.930520\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:58.897759\"}" tags="[]"}
`<font size="3" color="black">`{=html} Now we are going to test using
some completely unseen and differently styled images. This data-set also
includes a huge variety of ages from babies all the way to elderly. So
we are not expecting the results to be accurate, but still a fun
experiment to see how it might play out in a real world environment!
:::

::: {.cell .code execution_count="17" execution="{\"iopub.status.busy\":\"2022-10-17T16:01:58.998297Z\",\"iopub.status.idle\":\"2022-10-17T16:02:35.092845Z\",\"iopub.execute_input\":\"2022-10-17T16:01:58.998683Z\",\"shell.execute_reply\":\"2022-10-17T16:02:35.091955Z\"}" papermill="{\"status\":\"completed\",\"duration\":36.185746,\"end_time\":\"2022-10-17T16:02:35.149477\",\"exception\":false,\"start_time\":\"2022-10-17T16:01:58.963731\"}" tags="[]"}
``` {.python}
img_prediction(unknown_data,4,4)
```

::: {.output .display_data}
![](vertopal_04cb403177b04b4cbbc6e5647ef19996/2ecc66aa012fc956b9b16f5e4da95a123dac9f1d.png)
:::
:::

::: {.cell .code papermill="{\"status\":\"completed\",\"duration\":4.5128e-2,\"end_time\":\"2022-10-17T16:02:35.240667\",\"exception\":false,\"start_time\":\"2022-10-17T16:02:35.195539\"}" tags="[]"}
``` {.python}
```
:::
